{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy GAP Analyzer\n",
    "\n",
    "> The input to this API is a zipped file containing Standard's JSON and Policy_JSON. The API splits the controls from the standard and then compares each control against the given policy. This allows the system to generate a gap analysis report, which is output as a ZIP (GAP_JSON) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp policy/policy_gap_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from app.policy.helper.llm_functions import init_azure_llm\n",
    "from app.policy.helper.prompts import policy_gap_prompt_template, policy_gap_output\n",
    "import concurrent.futures\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_policy_gap(\n",
    "    llm, # LLM object\n",
    "    domain, # single domain object of given standard\n",
    "    policy, # entire policy object\n",
    "    standard_name # standard name\n",
    "):\n",
    "    ONE_DOMAIN = domain\n",
    "    ONE_DOMAIN['standard_name']=standard_name\n",
    "    ONE_DOMAIN = f\"\"\"\n",
    "        ```json \n",
    "        {str(ONE_DOMAIN)}\n",
    "        ```\"\"\"\n",
    "    input_policy_str = f\"\"\"\n",
    "        ```json\n",
    "        {str(policy)}\n",
    "        ```\"\"\"\n",
    "    \n",
    "    prompt = policy_gap_prompt_template.format(input_policy=input_policy_str,input_standard=ONE_DOMAIN,output_str=policy_gap_output)\n",
    "    response = llm.bind(response_format={\"type\": \"json_object\"}).invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def policy_gap_summary(\n",
    "    llm, # LLM object\n",
    "    policy_gap_resp # LLM responses of all domain\n",
    "):\n",
    "    # Combine gap_analysis descriptions\n",
    "    combined_description = \" \".join([json.loads(resp.content)['gap_analysis']['description'] for resp in policy_gap_resp])\n",
    "\n",
    "    # Summarize the combined description using llm\n",
    "    summary_response = llm.invoke(f\"Summarize the following text: {combined_description}\")\n",
    "    summary_description = summary_response.content.strip()\n",
    "\n",
    "    # Combine missing_controls and matching_controls\n",
    "    combined_missing_controls = []\n",
    "    combined_matching_controls = []\n",
    "\n",
    "    for resp in policy_gap_resp:\n",
    "        content = json.loads(resp.content)\n",
    "        combined_missing_controls.extend(content['controls_comparison']['missing_controls'])\n",
    "        combined_matching_controls.extend(content['controls_comparison']['matching_controls'])\n",
    "\n",
    "    # Create the combined output\n",
    "    combined_output = {\n",
    "        \"status\": \"success\",\n",
    "        \"gap_analysis\": {\n",
    "            \"description\": summary_description\n",
    "        },\n",
    "        \"controls_comparison\": {\n",
    "            \"missing_controls\": combined_missing_controls,\n",
    "            \"matching_controls\": combined_matching_controls\n",
    "        }\n",
    "    }\n",
    "    return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def policy_gap_processor(input_data): # input data [Policy, Standard]\n",
    "    policy_gap_resp = []\n",
    "    print('policy gap analyzer api process started')\n",
    "    llm = init_azure_llm()\n",
    "    [input_policy, input_standard] = input_data\n",
    "    standard_name = input_standard['standard_name']\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(generate_policy_gap, llm,domain,input_policy,standard_name) for domain in input_standard['domains']]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            policy_gap_resp.append(future.result())\n",
    "\n",
    "    combined_output = policy_gap_summary(llm, policy_gap_resp)\n",
    "    print('policy gap analyzer api process Completed')\n",
    "    return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
